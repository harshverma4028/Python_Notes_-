{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZsmdM0NY92Y"
      },
      "source": [
        "#Task 1: Import Libraries and Define the OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WAbalTS5Wp4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7daf07d0-8731-44f8-a5e1-886cf56313f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.65.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.65.1-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-1.65.1\n"
          ]
        }
      ],
      "source": [
        "# ! pip install openai\n",
        "! pip install openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sKePH20SW5aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f6fc8f-5cf5-4c20-9843-1fcb156b3554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.65.1\n",
            "    Uninstalling openai-1.65.1:\n",
            "      Successfully uninstalled openai-1.65.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "! pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IwaIzzF4WsDT"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# go to \"https://platform.openai.com/api-keys\" to get your api key\n",
        "\n",
        "# Define OpenAI API key\n",
        "openai.api_key = \"API KEY HERE\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMBxHl5afnho"
      },
      "source": [
        "#Task 2: Chat with ChatGPT using the API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MDBUWcq-fqPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "bd2298ca-3a85-477a-aa00-57d3c1cc23e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: what is the color of parrot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Incorrect API key provided: API KEY HERE. You can find your API key at https://platform.openai.com/account/api-keys.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3901a24818e1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Generate a response from ChatGPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ChatGPT: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mconversation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ChatGPT: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3901a24818e1>\u001b[0m in \u001b[0;36mchat_with_gpt\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function to send a message to ChatGPT and get a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Updated to a supported model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: API KEY HERE. You can find your API key at https://platform.openai.com/account/api-keys."
          ]
        }
      ],
      "source": [
        "# Function to send a message to ChatGPT and get a response\n",
        "def chat_with_gpt(message):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo\",  # Updated to a supported model\n",
        "        prompt=message,\n",
        "        max_tokens=50  # Adjust this based on your desired response length\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\n",
        "# Start a conversation\n",
        "conversation = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    conversation.append(f\"You: {user_input}\")\n",
        "\n",
        "    # Exit the loop if the user wants to end the conversation\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Generate a response from ChatGPT\n",
        "    response = chat_with_gpt(\"\\n\".join(conversation))\n",
        "    print(f\"ChatGPT: {response}\")\n",
        "    conversation.append(f\"ChatGPT: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUu9y6EzZSKl"
      },
      "source": [
        "#Task 3: Define the Chatbot Conversation Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9wn1GojXHIt"
      },
      "outputs": [],
      "source": [
        "def chatbot_conversation(initial_prompt):\n",
        "    # Initialize conversation with initial prompt\n",
        "    prompt = initial_prompt\n",
        "\n",
        "    # Continuously interact with the user until they end the conversation\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        # Send user input and current prompt to ChatGPT API and receive response\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\", # this model is specifically designed to understand and generate natural language text (instruction-following tasks)\n",
        "            prompt=prompt + \"\\nUser: \" + user_input,\n",
        "            temperature= 0.7, ### insert the temperature here ###\n",
        "            max_tokens= 1024 ### insert the max number tokens here ###\n",
        "        )\n",
        "\n",
        "        # Extract and display ChatGPT's response\n",
        "        chatbot_response = response.choices[0].text\n",
        "        print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "        # Update prompt for next iteration\n",
        "        prompt = prompt + \"\\nChatbot: \" + chatbot_response + \"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhfcrzXjZXFD"
      },
      "source": [
        "#Task 4: Handle Frequently Asked Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hje9d3v9i1g8"
      },
      "source": [
        "###Handling FAQs for Product Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y0Tvm6vXJmr"
      },
      "outputs": [],
      "source": [
        "def product_information_faq(user_input):\n",
        "    # Identify product-related keywords in user input\n",
        "    product_keywords = [\"product\", \"item\", \"details\", \"features\", \"specifications\", \"capabilities\"] ### insert product keywords here ###\n",
        "    for keyword in product_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant product information based on user's query\n",
        "            print(\"Please specify the product you're interested in and I'll provide more details.\")\n",
        "            product_name = input(\"Product name: \")\n",
        "            # Use product_name to retrieve and display product information from a database or API\n",
        "            print(\"Product information for \" + product_name + \":\")\n",
        "            # Display product details, features, and specifications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5fWR3z9ZcEU"
      },
      "source": [
        "###Handling FAQs for Shipping and Returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t0fDzC3XMCd"
      },
      "outputs": [],
      "source": [
        "def shipping_and_returns_faq(user_input):\n",
        "    # Identify shipping or returns keywords in user input\n",
        "    shipping_keywords = [\"shipping\", \"delivery\", \"courier\", \"timeline\"] ### insert product keywords here ###\n",
        "    returns_keywords = [\"return\", \"refund\", \"exchange\", \"policy\"]\n",
        "\n",
        "    for keyword in shipping_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant shipping information based on user's query\n",
        "            print(\"Shipping options and timelines for your order:\")\n",
        "            # Display shipping options, delivery timelines, and estimated delivery dates\n",
        "\n",
        "    for keyword in returns_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant returns information based on user's query\n",
        "            print(\"Our returns policy and procedures:\")\n",
        "            # Display returns policy, return initiation process, and refund or exchange options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjko2N6cZh-Q"
      },
      "source": [
        "###Handling FAQs for Customer Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNxR3k_UXOSh"
      },
      "outputs": [],
      "source": [
        "def customer_support_faq(user_input):\n",
        "    # Identify customer support keywords in user input\n",
        "    support_keywords = [\"help\", \"issue\", \"problem\", \"assistance\", \"support\"] ### insert product keywords here ###\n",
        "\n",
        "    for keyword in support_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant customer support assistance\n",
        "            print(\"Please describe your issue or problem in detail so we can assist you.\")\n",
        "            user_issue = input(\"Description of issue: \")\n",
        "            # Use user_issue to identify and resolve the user's problem or direct them to relevant support resources\n",
        "            print(\"We're here to help. Please provide more details about your issue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5EOYnzgZnFy"
      },
      "source": [
        "#Task 5: Initiate Chatbot Conversation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irKGuPtuXQ8R"
      },
      "outputs": [],
      "source": [
        "# Start the chatbot conversation with a welcome message\n",
        "print(\"Welcome to our customer service chatbot. How can I help you today?\")\n",
        "\n",
        "# Initialize conversation with an empty prompt\n",
        "prompt = \"\"\n",
        "\n",
        "# Continuously interact with the user and handle their queries\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # Check if user wants to end the conversation\n",
        "    if user_input.lower() == \"bye\" or user_input.lower() == \"quit\":\n",
        "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Construct the prompt for ChatGPT API\n",
        "    prompt += \"\\nUser: \" + user_input\n",
        "\n",
        "    # Send user input and current prompt to ChatGPT API and receive response\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    # Extract and display ChatGPT's response\n",
        "    chatbot_response = response.choices[0].text\n",
        "\n",
        "    # Skip empty responses\n",
        "    if not chatbot_response:\n",
        "        continue\n",
        "\n",
        "    print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "    # Update prompt for next iteration\n",
        "    prompt += \"\\nChatbot: \" + chatbot_response + \"\\n\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-tSslz4b8df"
      },
      "source": [
        "#Task 6: Build a Customized Chatbot and Chat with It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jhR3p6ADc_m2"
      },
      "outputs": [],
      "source": [
        "# Import the OpenAI library\n",
        "import openai\n",
        "\n",
        "# Start the chatbot conversation with a welcome message\n",
        "print(\"Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\")\n",
        "\n",
        "# Initialize conversation with a system message to set the context for ChatGPT\n",
        "prompt = \"System: You are a customer service AI knowledgeable about ebooks.\\\\n\"\n",
        "\n",
        "# Continuously interact with the user and handle their queries\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # Check if user wants to end the conversation\n",
        "    if user_input.lower() in [\"bye\", \"quit\"]:\n",
        "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Add user input to prompt\n",
        "    prompt += \"User: \" + user_input + \"\\\\n\"\n",
        "\n",
        "    # Send user input and current prompt to ChatGPT API and receive response\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=150,\n",
        "        stop=[\"\\\\n\", \" User:\", \" System:\"]\n",
        "    )\n",
        "\n",
        "    # Extract and display ChatGPT's response\n",
        "    chatbot_response = response.choices[0].text.strip()\n",
        "\n",
        "    # Skip empty responses\n",
        "    if not chatbot_response:\n",
        "        continue\n",
        "\n",
        "    # Check if the user's query is off-topic\n",
        "    if \"ebook\" not in user_input.lower() and \"book\" not in user_input.lower() and any(word in chatbot_response.lower() for word in [\"sorry\", \"don't know\", \"not sure\"]):\n",
        "        print(\"Chatbot: I'm sorry, I specialize in ebooks. Could you please ask something related to that topic?\")\n",
        "    else:\n",
        "        print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "    # Update prompt for next iteration\n",
        "    prompt += \"Chatbot: \" + chatbot_response + \"\\\\n\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n"
      ],
      "metadata": {
        "id": "PminFKjlYplx",
        "outputId": "923eec65-2e7a-4fcb-f4a8-f5d8fd41b3ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.68.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the Genai**"
      ],
      "metadata": {
        "id": "2F3Wpce6aJXJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5OQV8KnyggaX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "8cf21f17-21c7-4291-f4eb-8d6c77c95309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\n",
            "User: hii\n",
            "Chatbot: Hi there! How can I help you with your ticket booking today?\n",
            "User: what can you do for me \n",
            "Chatbot: I can assist you with a variety of ticket booking-related tasks, such as:\n",
            "\n",
            "* **Searching for tickets:** I can help you find tickets for events, flights, trains, buses, concerts, shows, and more.  Just tell me what you're looking for (e.g., \"flights from New York to London in October,\" \"tickets to the Taylor Swift concert in Chicago,\" \"train tickets from Boston to Washington D.C.\").\n",
            "* **Comparing prices:** I can help you compare prices from different vendors to find the best deals.\n",
            "* **Checking availability:** I can check the availability of tickets for specific dates and times.\n",
            "* **Providing information about venues:** I can provide information about venue locations, seating charts, and accessibility.\n",
            "* **Answering questions about baggage allowances, cancellation policies, and other travel-related queries.**\n",
            "* **Offering tips and advice on booking tickets and planning your trip.**\n",
            "\n",
            "Essentially, I can be your virtual ticket booking assistant. Tell me what you need, and I'll do my best to help!\n",
            "User: check the flight for tha jaiprkash narayan international airport\n",
            "Chatbot: Okay, I can help you check flights for Jai Prakash Narayan International Airport (PAT). To give you the most relevant results, I need some more information:\n",
            "\n",
            "* **Are you looking for arriving or departing flights?**\n",
            "* **What is your destination (if departing) or origin (if arriving)?**\n",
            "* **What dates are you looking to travel?**\n",
            "* **How many passengers?**\n",
            "* **Are you looking for one-way or round-trip flights?**\n",
            "\n",
            "Once I have this information, I can search for available flights and provide you with options.\n",
            "User: i am 1 passenger \n",
            "Chatbot: Okay, you're one passenger.  We still need a few more details to find the right flights for you:\n",
            "\n",
            "* **Are you arriving at or departing from Patna Airport (PAT)?**\n",
            "* **Where are you traveling to (if departing) or coming from (if arriving)?**\n",
            "* **What dates are you looking to travel?**\n",
            "* **Do you want a one-way or a round-trip ticket?**\n",
            "User: by\n",
            "Chatbot: \"By\" usually means you're looking for transportation methods. Did you want to check flights *by* a specific airline, or did you mean something else?  Please clarify your request so I can assist you.\n",
            "\n",
            "For example, you could say:\n",
            "\n",
            "* \"Flights *from* Patna *to* Delhi\"\n",
            "* \"Flights *by* IndiGo *from* Patna\"\n",
            "\n",
            "\n",
            "Providing more details will help me find the information you're looking for.\n",
            "User: bye\n",
            "Thank you for using our chatbot. Have a great day!\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Gemini API key\n",
        "genai.configure(api_key=\"yanha api key aayega\")  # Replace with your actual API key\n",
        "\n",
        "# Load the Gemini model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "\n",
        "# Welcome message\n",
        "print(\"Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\")\n",
        "\n",
        "conversation = [\n",
        "    {\"role\": \"user\", \"parts\": [\"You are a customer service AI knowledgeable about ebook.\"]}\n",
        "]\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    if user_input.lower() in [\"bye\", \"quit\"]:\n",
        "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    conversation.append({\"role\": \"user\", \"parts\": [user_input]})\n",
        "\n",
        "    # Generate response from Gemini\n",
        "    response = model.generate_content(conversation)\n",
        "\n",
        "    chatbot_response = response.text.strip()\n",
        "\n",
        "    if not chatbot_response:\n",
        "        continue\n",
        "\n",
        "    # Keep chatbot responses relevant to ebooks\n",
        "    if \"ebook\" not in user_input.lower() and \"book\" not in user_input.lower() and any(word in chatbot_response.lower() for word in [\"sorry\", \"don't know\", \"not sure\"]):\n",
        "        print(\"Chatbot: I'm sorry, I specialize in ebooks. Could you please ask something related to that topic?\")\n",
        "    else:\n",
        "        print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "    conversation.append({\"role\": \"model\", \"parts\": [chatbot_response]})\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}